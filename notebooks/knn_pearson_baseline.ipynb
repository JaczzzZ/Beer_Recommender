{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext nb_black\";\n                var nbb_formatted_code = \"%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"import os\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom surprise import Dataset\\nfrom surprise import Reader\\nfrom surprise.model_selection import cross_validate\\nfrom surprise import KNNBasic\\nfrom surprise.model_selection import train_test_split\\nfrom surprise import dump\\nimport csv\\nfrom surprise import accuracy\\nfrom pprint import pprint\";\n                var nbb_formatted_code = \"import os\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom surprise import Dataset\\nfrom surprise import Reader\\nfrom surprise.model_selection import cross_validate\\nfrom surprise import KNNBasic\\nfrom surprise.model_selection import train_test_split\\nfrom surprise import dump\\nimport csv\\nfrom surprise import accuracy\\nfrom pprint import pprint\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import dump\n",
    "import csv\n",
    "from surprise import accuracy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"csv_path = os.path.join(\\\"../data/csv/reviews_cleaned_reduced_500.csv\\\")\\nTextFileReader = pd.read_csv(csv_path, chunksize=1000)  # the number of rows per chunk\\n\\ndfList = []\\nfor df in TextFileReader:\\n    dfList.append(df)\\n\\ndf = pd.concat(dfList,sort=False)\";\n                var nbb_formatted_code = \"csv_path = os.path.join(\\\"../data/csv/reviews_cleaned_reduced_500.csv\\\")\\nTextFileReader = pd.read_csv(csv_path, chunksize=1000)  # the number of rows per chunk\\n\\ndfList = []\\nfor df in TextFileReader:\\n    dfList.append(df)\\n\\ndf = pd.concat(dfList, sort=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = os.path.join(\"../data/csv/reviews_cleaned_reduced_500.csv\")\n",
    "TextFileReader = pd.read_csv(csv_path, chunksize=1000)  # the number of rows per chunk\n",
    "\n",
    "dfList = []\n",
    "for df in TextFileReader:\n",
    "    dfList.append(df)\n",
    "\n",
    "df = pd.concat(dfList,sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# load beers\\ncsv_path = os.path.join(\\\"../data/csv/beers.csv\\\")\\nbeers_df = pd.read_csv(csv_path)\";\n                var nbb_formatted_code = \"# load beers\\ncsv_path = os.path.join(\\\"../data/csv/beers.csv\\\")\\nbeers_df = pd.read_csv(csv_path)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load beers\n",
    "csv_path = os.path.join(\"../data/csv/beers.csv\")\n",
    "beers_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"beers_df = beers_df.rename(columns={'id': 'beer_id'})\";\n                var nbb_formatted_code = \"beers_df = beers_df.rename(columns={\\\"id\\\": \\\"beer_id\\\"})\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beers_df = beers_df.rename(columns={'id': 'beer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# Lets combine the dataframe\\nmerge_df = pd.merge(df,\\n                 beers_df[['beer_id', 'name', 'style', 'brewery_id']],\\n                 on='beer_id')\";\n                var nbb_formatted_code = \"# Lets combine the dataframe\\nmerge_df = pd.merge(\\n    df, beers_df[[\\\"beer_id\\\", \\\"name\\\", \\\"style\\\", \\\"brewery_id\\\"]], on=\\\"beer_id\\\"\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets combine the dataframe\n",
    "merge_df = pd.merge(df,\n",
    "                 beers_df[['beer_id', 'name', 'style', 'brewery_id']],\n",
    "                 on='beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.4694\n",
      "MAE:  0.3390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33899617725544373"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# sample random trainset and testset method using Pearson similarity\\n# test set is made of 25% of the ratings. we are looking at similarities between items (user_based=false)\\nreader=Reader(rating_scale=(0,5))\\ndata = Dataset.load_from_df(merge_df[['username', 'beer_id', 'score']], reader)\\n\\ntrainset, testset = train_test_split(data, test_size=.25)\\n\\nsim_options = {'name': 'pearson_baseline',\\n               'user_based': False\\n               }\\n\\n# We'll use KNN.\\nalgo = KNNBasic(min_k = 10, sim_options=sim_options)\\n\\n# Train the algorithm on the trainset, and predict ratings for the testset\\nalgo.fit(trainset)\\npredictions = algo.fit(trainset).test(testset)\\n\\n# Then compute RMSE\\naccuracy.rmse(predictions)\\naccuracy.mae(predictions)\";\n                var nbb_formatted_code = \"# sample random trainset and testset method using Pearson similarity\\n# test set is made of 25% of the ratings. we are looking at similarities between items (user_based=false)\\nreader = Reader(rating_scale=(0, 5))\\ndata = Dataset.load_from_df(merge_df[[\\\"username\\\", \\\"beer_id\\\", \\\"score\\\"]], reader)\\n\\ntrainset, testset = train_test_split(data, test_size=0.25)\\n\\nsim_options = {\\\"name\\\": \\\"pearson_baseline\\\", \\\"user_based\\\": False}\\n\\n# We'll use KNN.\\nalgo = KNNBasic(min_k=10, sim_options=sim_options)\\n\\n# Train the algorithm on the trainset, and predict ratings for the testset\\nalgo.fit(trainset)\\npredictions = algo.fit(trainset).test(testset)\\n\\n# Then compute RMSE\\naccuracy.rmse(predictions)\\naccuracy.mae(predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample random trainset and testset method using Pearson similarity\n",
    "# test set is made of 25% of the ratings. we are looking at similarities between items (user_based=false)\n",
    "reader=Reader(rating_scale=(0,5))\n",
    "data = Dataset.load_from_df(merge_df[['username', 'beer_id', 'score']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "# We'll use KNN.\n",
    "algo = KNNBasic(min_k = 10, sim_options=sim_options)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.4645  0.4646  0.4617  0.4644  0.4648  0.4640  0.0012  \n",
      "MAE (testset)     0.3358  0.3355  0.3346  0.3352  0.3351  0.3352  0.0004  \n",
      "Fit time          13.72   18.09   13.53   13.58   13.89   14.56   1.77    \n",
      "Test time         30.56   21.87   19.45   19.04   19.42   22.07   4.36    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.46447705, 0.46460772, 0.46167093, 0.46438483, 0.46480734]),\n",
       " 'test_mae': array([0.33581497, 0.33550483, 0.3345594 , 0.33521422, 0.33505919]),\n",
       " 'fit_time': (13.716271877288818,\n",
       "  18.092827558517456,\n",
       "  13.532569408416748,\n",
       "  13.577640771865845,\n",
       "  13.886734247207642),\n",
       " 'test_time': (30.555680513381958,\n",
       "  21.87490749359131,\n",
       "  19.45203709602356,\n",
       "  19.041688442230225,\n",
       "  19.418246269226074)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# Five fold cross validation method to make sure our dataset is good\\nalgo = KNNBasic(min_k = 10, sim_options=sim_options)\\n\\n# Run 5-fold cross-validation and print results\\ncross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\";\n                var nbb_formatted_code = \"# Five fold cross validation method to make sure our dataset is good\\nalgo = KNNBasic(min_k=10, sim_options=sim_options)\\n\\n# Run 5-fold cross-validation and print results\\ncross_validate(algo, data, measures=[\\\"RMSE\\\", \\\"MAE\\\"], cv=5, verbose=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Five fold cross validation method to make sure our dataset is good\n",
    "algo = KNNBasic(min_k = 10, sim_options=sim_options)\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# Lets serialize and save this prediction algorithm\\n# Dump algorithm and reload it\\ndumpfile = os.path.join('../data/dump/dump_knn_pearson_500dump_file1')\\ndump.dump(dumpfile, predictions, algo)\";\n                var nbb_formatted_code = \"# Lets serialize and save this prediction algorithm\\n# Dump algorithm and reload it\\ndumpfile = os.path.join(\\\"../data/dump/dump_knn_pearson_500dump_file1\\\")\\ndump.dump(dumpfile, predictions, algo)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets serialize and save this prediction algorithm\n",
    "# Dump algorithm and reload it\n",
    "dumpfile = os.path.join('../data/dump/dump_knn_pearson_500dump_file1')\n",
    "dump.dump(dumpfile, predictions, algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"file_name_algo = os.path.join('../data/dump/algo_knn_pearson_500dump_file')\\ndump.dump(file_name_algo, algo=algo)\\nfile_name_pred = os.path.join('../data/dump/pred_knn_pearson_500dump_file')\\ndump.dump(file_name_pred, predictions=predictions)\";\n                var nbb_formatted_code = \"file_name_algo = os.path.join(\\\"../data/dump/algo_knn_pearson_500dump_file\\\")\\ndump.dump(file_name_algo, algo=algo)\\nfile_name_pred = os.path.join(\\\"../data/dump/pred_knn_pearson_500dump_file\\\")\\ndump.dump(file_name_pred, predictions=predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name_algo = os.path.join('../data/dump/algo_knn_pearson_500dump_file')\n",
    "dump.dump(file_name_algo, algo=algo)\n",
    "file_name_pred = os.path.join('../data/dump/pred_knn_pearson_500dump_file')\n",
    "dump.dump(file_name_pred, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# Code below identifes the top 10 best and worst predictions based upon code from this \\n# notebook:https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb\\ndef get_Iu(uid):\\n    \\\"\\\"\\\" return the number of items rated by given user\\n    args: \\n      uid: the id of the user\\n    returns: \\n      the number of items rated by the user\\n    \\\"\\\"\\\"\\n    try:\\n        return len(trainset.ur[trainset.to_inner_uid(uid)])\\n    except ValueError: # user was not part of the trainset\\n        return 0\\n    \\ndef get_Ui(iid):\\n    \\\"\\\"\\\" return number of users that have rated given item\\n    args:\\n      iid: the raw id of the item\\n    returns:\\n      the number of users that have rated the item.\\n    \\\"\\\"\\\"\\n    try: \\n        return len(trainset.ir[trainset.to_inner_iid(iid)])\\n    except ValueError:\\n        return 0\\n    \\ndef get_inner_ids(riid):\\n    inner_ids = []\\n    for riid in riids:\\n        inner_ids.append(trainset.to_inner_iid(riid))\\n    return inner_ids\\n        \\n    \\ndf_predict = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\\ndf_predict['Iu'] = df_predict.uid.apply(get_Iu)\\ndf_predict['Ui'] = df_predict.iid.apply(get_Ui)\\ndf_predict['err'] = abs(df_predict.est - df_predict.rui)\\nbest_predictions = df_predict.sort_values(by='err')[:10]\\nworst_predictions = df_predict.sort_values(by='err')[-10:]\";\n                var nbb_formatted_code = \"# Code below identifes the top 10 best and worst predictions based upon code from this\\n# notebook:https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb\\ndef get_Iu(uid):\\n    \\\"\\\"\\\" return the number of items rated by given user\\n    args: \\n      uid: the id of the user\\n    returns: \\n      the number of items rated by the user\\n    \\\"\\\"\\\"\\n    try:\\n        return len(trainset.ur[trainset.to_inner_uid(uid)])\\n    except ValueError:  # user was not part of the trainset\\n        return 0\\n\\n\\ndef get_Ui(iid):\\n    \\\"\\\"\\\" return number of users that have rated given item\\n    args:\\n      iid: the raw id of the item\\n    returns:\\n      the number of users that have rated the item.\\n    \\\"\\\"\\\"\\n    try:\\n        return len(trainset.ir[trainset.to_inner_iid(iid)])\\n    except ValueError:\\n        return 0\\n\\n\\ndef get_inner_ids(riid):\\n    inner_ids = []\\n    for riid in riids:\\n        inner_ids.append(trainset.to_inner_iid(riid))\\n    return inner_ids\\n\\n\\ndf_predict = pd.DataFrame(predictions, columns=[\\\"uid\\\", \\\"iid\\\", \\\"rui\\\", \\\"est\\\", \\\"details\\\"])\\ndf_predict[\\\"Iu\\\"] = df_predict.uid.apply(get_Iu)\\ndf_predict[\\\"Ui\\\"] = df_predict.iid.apply(get_Ui)\\ndf_predict[\\\"err\\\"] = abs(df_predict.est - df_predict.rui)\\nbest_predictions = df_predict.sort_values(by=\\\"err\\\")[:10]\\nworst_predictions = df_predict.sort_values(by=\\\"err\\\")[-10:]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code below identifes the top 10 best and worst predictions based upon code from this \n",
    "# notebook:https://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb\n",
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "def get_inner_ids(riid):\n",
    "    inner_ids = []\n",
    "    for riid in riids:\n",
    "        inner_ids.append(trainset.to_inner_iid(riid))\n",
    "    return inner_ids\n",
    "        \n",
    "    \n",
    "df_predict = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df_predict['Iu'] = df_predict.uid.apply(get_Iu)\n",
    "df_predict['Ui'] = df_predict.iid.apply(get_Ui)\n",
    "df_predict['err'] = abs(df_predict.est - df_predict.rui)\n",
    "best_predictions = df_predict.sort_values(by='err')[:10]\n",
    "worst_predictions = df_predict.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 uid     iid  rui  est  \\\n",
      "74887   DrunkyBuddha   72170  5.0  5.0   \n",
      "38995    IAMTEAMPONY      92  3.0  3.0   \n",
      "217274      bmcduff2     103  1.0  1.0   \n",
      "34358       bmcduff2     108  1.0  1.0   \n",
      "144234     100200300    5948  3.0  3.0   \n",
      "13032       bmcduff2    1054  1.0  1.0   \n",
      "22017      100200300    6260  3.0  3.0   \n",
      "104406      bmcduff2    1341  1.0  1.0   \n",
      "189487  PC_Principal  109989  5.0  5.0   \n",
      "138459   IAMTEAMPONY   15758  3.0  3.0   \n",
      "\n",
      "                                          details  Iu    Ui  err  \n",
      "74887   {'actual_k': 32, 'was_impossible': False}  54  1223  0.0  \n",
      "38995   {'actual_k': 28, 'was_impossible': False}  50  2251  0.0  \n",
      "217274  {'actual_k': 17, 'was_impossible': False}  21  1320  0.0  \n",
      "34358   {'actual_k': 17, 'was_impossible': False}  21   861  0.0  \n",
      "144234  {'actual_k': 24, 'was_impossible': False}  46   493  0.0  \n",
      "13032   {'actual_k': 12, 'was_impossible': False}  21   748  0.0  \n",
      "22017   {'actual_k': 21, 'was_impossible': False}  46  1536  0.0  \n",
      "104406  {'actual_k': 18, 'was_impossible': False}  21   442  0.0  \n",
      "189487  {'actual_k': 32, 'was_impossible': False}  43   414  0.0  \n",
      "138459  {'actual_k': 25, 'was_impossible': False}  50   886  0.0  \n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# Best Predictions:\\nprint(best_predictions)\";\n                var nbb_formatted_code = \"# Best Predictions:\\nprint(best_predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best Predictions:\n",
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       uid    iid   rui       est  \\\n",
      "31272             YogiBeer  72720  1.00  4.324069   \n",
      "219610            OzmanBey    141  1.00  4.337622   \n",
      "76702             IvanJ126    332  1.00  4.355096   \n",
      "80415              jmiah22    567  1.00  4.437230   \n",
      "76732     Sails_Ambassador   1585  1.00  4.459066   \n",
      "5142           cclark67789     92  1.00  4.486041   \n",
      "65205           jallen5076  88880  1.28  4.772604   \n",
      "130600       nathanjohnson  55939  1.00  4.513062   \n",
      "1066                  dwaz   7520  1.24  4.782613   \n",
      "121245  LloydBobBoozehound  30420  1.00  4.551155   \n",
      "\n",
      "                                          details  Iu    Ui       err  \n",
      "31272   {'actual_k': 14, 'was_impossible': False}  42   432  3.324069  \n",
      "219610  {'actual_k': 23, 'was_impossible': False}  43  1526  3.337622  \n",
      "76702   {'actual_k': 10, 'was_impossible': False}  23   970  3.355096  \n",
      "80415   {'actual_k': 15, 'was_impossible': False}  59   641  3.437230  \n",
      "76732   {'actual_k': 13, 'was_impossible': False}  27  1058  3.459066  \n",
      "5142    {'actual_k': 35, 'was_impossible': False}  53  2251  3.486041  \n",
      "65205   {'actual_k': 24, 'was_impossible': False}  38   533  3.492604  \n",
      "130600  {'actual_k': 28, 'was_impossible': False}  54  1567  3.513062  \n",
      "1066    {'actual_k': 20, 'was_impossible': False}  38  1071  3.542613  \n",
      "121245  {'actual_k': 12, 'was_impossible': False}  14  2147  3.551155  \n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"# Worst Predictions:\\nprint(worst_predictions)\";\n                var nbb_formatted_code = \"# Worst Predictions:\\nprint(worst_predictions)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Worst Predictions:\n",
    "print(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"def get_beer_name (beer_raw_id):\\n    beer_name = beers_df.loc[beers_df.beer_id==beer_raw_id,'name'].values[0]\\n    return beer_name\\n\\ndef get_beer_style (beer_raw_id):\\n    beer_style = beers_df.loc[beers_df.beer_id==beer_raw_id,'style'].values[0]\\n    return beer_style\\n\\ndef get_beer_score_mean (beer_raw_id):\\n    score_mean = mean_score.loc[mean_score.beer_id==beer_raw_id,'score'].values[0]\\n    return score_mean\\n\\ndef get_beer_neighbors (beer_raw_id):\\n    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\\n    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\\n    beer_neighbors = (algo.trainset.to_raw_iid(inner_id)\\n                  for inner_id in beer_neighbors)\\n    return(beer_neighbors)\\n\\ndef get_beer_recc_df (beer_raw_id):\\n    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\\n    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\\n    beer_neighbors = (algo.trainset.to_raw_iid(inner_id)\\n                      for inner_id in beer_neighbors)\\n    beers_id_recc = []\\n    beer_name_recc =[]\\n    beer_style_recc = []\\n    beer_score_mean = []\\n    for beer in beer_neighbors:\\n        beers_id_recc.append(beer)\\n        beer_name_recc.append(get_beer_name(beer))\\n        beer_style_recc.append(get_beer_style(beer))\\n        beer_score_mean.append(get_beer_score_mean(beer))\\n    beer_reccomendations_df = pd.DataFrame(list(zip(beers_id_recc,beer_name_recc,beer_style_recc,beer_score_mean)),\\n                                       columns=['beer_id', 'name', 'style', 'score_mean'])\\n    return beer_reccomendations_df\\n    \\ndef get_inner_ids(riids):\\n    inner_ids = []\\n    for riid in riids:\\n        inner_ids.append(trainset.to_inner_iid(riid))\\n    return inner_ids\\n        \";\n                var nbb_formatted_code = \"def get_beer_name(beer_raw_id):\\n    beer_name = beers_df.loc[beers_df.beer_id == beer_raw_id, \\\"name\\\"].values[0]\\n    return beer_name\\n\\n\\ndef get_beer_style(beer_raw_id):\\n    beer_style = beers_df.loc[beers_df.beer_id == beer_raw_id, \\\"style\\\"].values[0]\\n    return beer_style\\n\\n\\ndef get_beer_score_mean(beer_raw_id):\\n    score_mean = mean_score.loc[mean_score.beer_id == beer_raw_id, \\\"score\\\"].values[0]\\n    return score_mean\\n\\n\\ndef get_beer_neighbors(beer_raw_id):\\n    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\\n    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\\n    beer_neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in beer_neighbors)\\n    return beer_neighbors\\n\\n\\ndef get_beer_recc_df(beer_raw_id):\\n    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\\n    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\\n    beer_neighbors = (algo.trainset.to_raw_iid(inner_id) for inner_id in beer_neighbors)\\n    beers_id_recc = []\\n    beer_name_recc = []\\n    beer_style_recc = []\\n    beer_score_mean = []\\n    for beer in beer_neighbors:\\n        beers_id_recc.append(beer)\\n        beer_name_recc.append(get_beer_name(beer))\\n        beer_style_recc.append(get_beer_style(beer))\\n        beer_score_mean.append(get_beer_score_mean(beer))\\n    beer_reccomendations_df = pd.DataFrame(\\n        list(zip(beers_id_recc, beer_name_recc, beer_style_recc, beer_score_mean)),\\n        columns=[\\\"beer_id\\\", \\\"name\\\", \\\"style\\\", \\\"score_mean\\\"],\\n    )\\n    return beer_reccomendations_df\\n\\n\\ndef get_inner_ids(riids):\\n    inner_ids = []\\n    for riid in riids:\\n        inner_ids.append(trainset.to_inner_iid(riid))\\n    return inner_ids\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_beer_name (beer_raw_id):\n",
    "    beer_name = beers_df.loc[beers_df.beer_id==beer_raw_id,'name'].values[0]\n",
    "    return beer_name\n",
    "\n",
    "def get_beer_style (beer_raw_id):\n",
    "    beer_style = beers_df.loc[beers_df.beer_id==beer_raw_id,'style'].values[0]\n",
    "    return beer_style\n",
    "\n",
    "def get_beer_score_mean (beer_raw_id):\n",
    "    score_mean = mean_score.loc[mean_score.beer_id==beer_raw_id,'score'].values[0]\n",
    "    return score_mean\n",
    "\n",
    "def get_beer_neighbors (beer_raw_id):\n",
    "    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\n",
    "    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\n",
    "    beer_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                  for inner_id in beer_neighbors)\n",
    "    return(beer_neighbors)\n",
    "\n",
    "def get_beer_recc_df (beer_raw_id):\n",
    "    beer_inner_id = algo.trainset.to_inner_iid(beer_raw_id)\n",
    "    beer_neighbors = algo.get_neighbors(beer_inner_id, k=10)\n",
    "    beer_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                      for inner_id in beer_neighbors)\n",
    "    beers_id_recc = []\n",
    "    beer_name_recc =[]\n",
    "    beer_style_recc = []\n",
    "    beer_score_mean = []\n",
    "    for beer in beer_neighbors:\n",
    "        beers_id_recc.append(beer)\n",
    "        beer_name_recc.append(get_beer_name(beer))\n",
    "        beer_style_recc.append(get_beer_style(beer))\n",
    "        beer_score_mean.append(get_beer_score_mean(beer))\n",
    "    beer_reccomendations_df = pd.DataFrame(list(zip(beers_id_recc,beer_name_recc,beer_style_recc,beer_score_mean)),\n",
    "                                       columns=['beer_id', 'name', 'style', 'score_mean'])\n",
    "    return beer_reccomendations_df\n",
    "    \n",
    "def get_inner_ids(riids):\n",
    "    inner_ids = []\n",
    "    for riid in riids:\n",
    "        inner_ids.append(trainset.to_inner_iid(riid))\n",
    "    return inner_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"#Create mean score dataframe and get riids (riids = raw beers ids)\\nmean_score = merge_df.groupby('beer_id', as_index=False)[['score']].mean()\\nriids = mean_score['beer_id']\\nriids = riids.to_list()\\n#Get the beer inner ids\\ninner_ids = get_inner_ids(riids)\";\n                var nbb_formatted_code = \"# Create mean score dataframe and get riids (riids = raw beers ids)\\nmean_score = merge_df.groupby(\\\"beer_id\\\", as_index=False)[[\\\"score\\\"]].mean()\\nriids = mean_score[\\\"beer_id\\\"]\\nriids = riids.to_list()\\n# Get the beer inner ids\\ninner_ids = get_inner_ids(riids)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create mean score dataframe and get riids (riids = raw beers ids)\n",
    "mean_score = merge_df.groupby('beer_id', as_index=False)[['score']].mean()\n",
    "riids = mean_score['beer_id']\n",
    "riids = riids.to_list()\n",
    "#Get the beer inner ids\n",
    "inner_ids = get_inner_ids(riids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"# Save the df_predict and df_ids for later use\\ndf_predict.to_csv(\\\"../data/csv/df_predict_pearsonbaseline_500.csv\\\",index=False)\\ndf_ids = pd.DataFrame(list(zip(riids,inner_ids)), columns=['beer_id', 'inner_ids'])\\ndf_ids.to_csv(\\\"../data/csv/df_ids_pearsonbaseline_500.csv\\\",index=False)\";\n                var nbb_formatted_code = \"# Save the df_predict and df_ids for later use\\ndf_predict.to_csv(\\\"../data/csv/df_predict_pearsonbaseline_500.csv\\\", index=False)\\ndf_ids = pd.DataFrame(list(zip(riids, inner_ids)), columns=[\\\"beer_id\\\", \\\"inner_ids\\\"])\\ndf_ids.to_csv(\\\"../data/csv/df_ids_pearsonbaseline_500.csv\\\", index=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the df_predict and df_ids for later use\n",
    "df_predict.to_csv(\"../data/csv/df_predict_pearsonbaseline_500.csv\",index=False)\n",
    "df_ids = pd.DataFrame(list(zip(riids,inner_ids)), columns=['beer_id', 'inner_ids'])\n",
    "df_ids.to_csv(\"../data/csv/df_ids_pearsonbaseline_500.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"# Create pickles of our dataframes to be used in the load program\\n\\nfilter_df = merge_df.drop(['username', 'score'], axis=1).drop_duplicates(subset =\\n                                                                        ['beer_id',\\n                                                                        'name',\\n                                                                        'style',\\n                                                                        'brewery_id'],\\n                                                                        keep=\\\"first\\\")\\niids_merged = pd.merge(df_ids, mean_score[['beer_id', 'score']], on='beer_id')\";\n                var nbb_formatted_code = \"# Create pickles of our dataframes to be used in the load program\\n\\nfilter_df = merge_df.drop([\\\"username\\\", \\\"score\\\"], axis=1).drop_duplicates(\\n    subset=[\\\"beer_id\\\", \\\"name\\\", \\\"style\\\", \\\"brewery_id\\\"], keep=\\\"first\\\"\\n)\\niids_merged = pd.merge(df_ids, mean_score[[\\\"beer_id\\\", \\\"score\\\"]], on=\\\"beer_id\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pickles of our dataframes to be used in the load program\n",
    "\n",
    "filter_df = merge_df.drop(['username', 'score'], axis=1).drop_duplicates(subset =\n",
    "                                                                        ['beer_id',\n",
    "                                                                        'name',\n",
    "                                                                        'style',\n",
    "                                                                        'brewery_id'],\n",
    "                                                                        keep=\"first\")\n",
    "iids_merged = pd.merge(df_ids, mean_score[['beer_id', 'score']], on='beer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"merged_iid_df = pd.merge(iids_merged,\\n                 filter_df[['beer_id', 'name', 'style', 'brewery_id']],\\n                 on='beer_id', )\";\n                var nbb_formatted_code = \"merged_iid_df = pd.merge(\\n    iids_merged, filter_df[[\\\"beer_id\\\", \\\"name\\\", \\\"style\\\", \\\"brewery_id\\\"]], on=\\\"beer_id\\\",\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_iid_df = pd.merge(iids_merged,\n",
    "                 filter_df[['beer_id', 'name', 'style', 'brewery_id']],\n",
    "                 on='beer_id', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"merged_iid_df.to_pickle(\\\"../data/dump/beer.pkl\\\")\\ndf_predict.to_pickle('../data/dump/df_predict.pkl')\";\n                var nbb_formatted_code = \"merged_iid_df.to_pickle(\\\"../data/dump/beer.pkl\\\")\\ndf_predict.to_pickle(\\\"../data/dump/df_predict.pkl\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_iid_df.to_pickle(\"../data/dump/beer.pkl\")\n",
    "df_predict.to_pickle('../data/dump/df_predict.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
